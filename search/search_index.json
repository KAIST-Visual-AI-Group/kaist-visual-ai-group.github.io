{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#kaist-visual-ai-group","title":"KAIST Visual AI Group","text":"<p>The KAIST Visual AI Group, led by Minhyuk Sung, conducts research on advancing technologies for generating, processing, and analyzing diverse visual data. Our work spans areas such as machine learning, computer vision, and computer graphics.</p> <p></p>"},{"location":"#research-highlights","title":"Research Highlights","text":"<p> Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation (ICCV 2025) A framework for vision-language models to perform spatial reasoning in arbitrary perspectives. <p></p> <p> VideoHandles: Editing 3D Object Compositions in Videos Using Video Generative Priors (CVPR 2025) The first method for 3D object composition editing in videos without any training. <p></p> <p> StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces (ICLR 2025) A method that combines diffusion synchronization and score distillation sampling for generating images in arbitrary spaces (e.g., 360\u00b0 panoramas and mesh textures). <p></p> <p> SyncTweedies: A General Generative Framework Based on Synchronized Diffusions (NeurIPS 2024) A novel approach for synchronizing multiple reverse diffusion processes to generate diverse visual content. <p></p> <p> Neural Pose Representation Learning for Generating and Transferring Non-Rigid Object Poses (NeurIPS 2024) A framework for learning neural pose representations that facilitate the generation and transfer of non-rigid object poses. <p></p> <p> Occupancy-Based Dual Contouring (SIGGRAPH Asia 2024) A dual contouring method that provides state-of-the-art performance for various neural implicit functions. <p></p> <p> ReGround: Improving Textual and Spatial Grounding at No Cost (ECCV 2024) A cost-free network reconfiguration for improving the text-prompt fidelity in layout-guided image generation. <p></p> <p> Posterior Distillation Sampling (CVPR 2024) A novel optimization method for editing parameterized images, applicable to NeRF, 3D Gaussian Splatting, and SVG. <p></p> <p> As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors (CVPR 2024) A plausibility-aware mesh deformation framework integrating Jacobian-based geometry representation and generative image priors. <p></p> <p> SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions (NeurIPS 2023) A zero-shot plug-and-play module that synchronizes multiple reverse diffusion processes, producing coherent images of various sizes. <p></p> <p> SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation (ICCV 2023) A cascaded diffusion model based on a part-level implicit 3D representation. <p></p> <p> PartGlot: Learning Shape Part Segmentation from Language Reference Games (CVPR 2022 (Oral)) A neural framework for learning semantic part segmentation of 3D shape geometry based solely on part referential language. <p></p> <p> OptCtrlPoints: Finding the Optimal Control Points for Biharmonic 3D Shape Deformation (Pacific Graphics 2023) A data-driven framework identifying the optimal sparse set of control points for biharmonic 3D shape deformation. <p></p>"},{"location":"#news","title":"News","text":"<ul> <li> <p>[Sep 2025] Five papers have been accepted to NeurIPS 2025, including one spotlight.</p> </li> <li> <p>[Sep 2025] One paper has been accepted to WACV 2026.</p> </li> <li> <p>[Aug 2025] Minhyuk talked about \"The Present and Future of Content Generation\" at the KAIST AI Transformation Workshop. Click to check out the recording.</p> </li> </ul> <p>View all</p>"},{"location":"#3d-gallery","title":"3D Gallery","text":""},{"location":"contact/","title":"Contact","text":""},{"location":"contact/#e-mail","title":"E-mail","text":"<p>mhsung (at) kaist.ac.kr</p>"},{"location":"contact/#phone","title":"Phone","text":"<p>+82-42-350-3587</p>"},{"location":"contact/#travel-information","title":"Travel Information","text":"<p>How to get to KAIST</p> <p>How to get to the KAIST Campus from Daejeon Station</p>"},{"location":"contact/#address","title":"Address","text":"<p>KAIST School of Computing</p> <p>Rm. 507, Bldg. E3-5 (KRAFTON Building),</p> <p>291 Daehak-ro, Yuseong-gu,</p> <p>Daejeon, South Korea 34141</p> <p></p>"},{"location":"courses/","title":"Courses","text":""},{"location":"courses/#2025","title":"2025","text":"<ul> <li> <p>CS479: Machine Learning for 3D Data (Spring 2025)</p> <p>This course discusses the recent advances in machine learning techniques for 3D data.</p> </li> <li> <p>CS492(C): Diffusion and Flow Models (Fall 2025)</p> <p>This course discusses the theoretical foundations and practical applications of diffusion and flow models.</p> </li> </ul>"},{"location":"courses/#2024","title":"2024","text":"<ul> <li> <p>CS580: Computer Graphics (Spring 2024)</p> <p>This course covers advanced topics in computer graphics, focusing on rendering.</p> </li> <li> <p>CS492(D): Diffusion Models and Their Applications (Fall 2024)</p> <p>This course discusses the theoretical foundations and practical applications of diffusion models.</p> </li> </ul>"},{"location":"courses/#2023","title":"2023","text":"<ul> <li> <p>CS380: Introduction to Computer Graphics (Spring 2023)</p> <p>This course provides an introduction to the fundamental concepts of computer graphics.</p> </li> <li> <p>CS479: Machine Learning for 3D Data (Fall 2023)</p> <p>This course discusses the recent advances in machine learning techniques for 3D data.</p> </li> </ul>"},{"location":"courses/#2022","title":"2022","text":"<ul> <li> <p>CS492(A): Machine Learning for 3D Data (Spring 2022)</p> <p>This course discusses the recent advances in machine learning techniques for 3D data.</p> </li> <li> <p>CS492(J): Geometric Modeling and Processing (Fall 2022)</p> <p>This course discusses fundamental mathematical methods for geometric 3D modeling and geometric data processing.</p> </li> </ul>"},{"location":"courses/#2021","title":"2021","text":"<ul> <li> <p>CS492(H): Machine Learning for 3D Data (Spring 2021)</p> <p>This course discusses the recent advances in machine learning techniques for 3D data.</p> </li> <li> <p>CS492(D): Geometric Modeling and Processing (Fall 2021)</p> <p>This course discusses fundamental mathematical methods for geometric 3D modeling and geometric data processing.</p> </li> </ul> <p></p>"},{"location":"internship/","title":"Internship","text":""},{"location":"internship/#call-for-internship-summer-2025-closed","title":"Call for Internship (Summer 2025) - Closed","text":""},{"location":"internship/#well-begin-hiring-winter-2025-interns-in-mid-october-2025-stay-tuned-for-more-updates","title":"We'll begin hiring Winter 2025 interns in mid-October 2025. Stay tuned for more updates!","text":""},{"location":"internship/#research-topics","title":"Research Topics","text":"<ul> <li>Diffusion models / Flow models / Autoregressive models<ul> <li>Discrete generative models</li> <li>Autoregressive diffusion models</li> <li>Large language diffusion models</li> <li>Video generative models</li> <li>Generative models across diverse data modalities</li> <li>Inference-time scaling</li> </ul> </li> <li>VLM / LLM / Foundation models<ul> <li>VLMs for spatial understanding</li> <li>RL-based fine-tuning of foundation models</li> </ul> </li> <li>3D / Neural rendering<ul> <li>3D generation, editing, and deformation</li> </ul> </li> </ul>"},{"location":"internship/#what-youll-do","title":"What You'll Do","text":"<p>As an intern, you'll have the opportunity to cultivate hands-on experience in research while participating in the following activities:</p> <ul> <li>Tutorials: Curated coding assignments covering recent research topics such as diffusion/flow models.</li> <li>Project: A small-scale research project based on an idea provided by our group. Interns are also welcome to pitch their own ideas for the project.</li> <li>Weekly Meetings: In-depth discussions on technical papers led by two student presenters (including both graduate and undergraduate students) every week.</li> <li>Paper Digest Meetings: Lightweight meetings for briefly skimming through recent papers.</li> </ul>"},{"location":"internship/#resources","title":"Resources","text":"<p>To find more information about our group, visit the followings:</p> <ul> <li>Group introduction slides (Oct 2024)</li> <li>Minhyuk's recent talk slides</li> <li>Publications page</li> <li>Course webpages<ul> <li>Diffusion Models and Their Applications (Fall 2024)</li> <li>Machine Learning for 3D Data (Spring 2025)</li> </ul> </li> </ul>"},{"location":"internship/#requirements","title":"Requirements","text":"<ul> <li>We're looking for students who have experience in developing any deep learning techniques.</li> <li>Candidates who have taken or audited the courses Diffusion Models and Their Applications and/or Machine Learning for 3D Data will be preferred (though this is not required).</li> <li>Interns will be required to be physically present in our lab during the internship.   Location: KAIST, N1 Bldg, Rm 622, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea 34141.</li> <li>Candidates who can extend the internship for the following semester will be preferred. (Remote work can be considered for the extension.)</li> </ul>"},{"location":"internship/#conditions","title":"Conditions","text":"<ul> <li>Interns will be expected to commit to the internship for full-time at least 8 weeks.</li> <li>Interns will be paid, and computing resources will be provided.Students enrolled in a university outside of Korea cannot be paid due to administrative restrictions.</li> </ul>"},{"location":"internship/#how-to-apply","title":"How to Apply","text":"<p>Click the ''Application Form'' button at the top. You'll need to prepare the following files:</p> <ul> <li>a copy of your transcript, and</li> <li>your CV/resume (including your previous experience in research, internship, or course projects, and your programming skills. Not required but recommended).</li> </ul>"},{"location":"internship/#contact","title":"Contact","text":"<p>mhsung (at) kaist.ac.kr</p>"},{"location":"internship/#faq","title":"FAQ","text":"<ul> <li> <p>Q. Can non-KAIST students apply? A. Yes.</p> </li> <li> <p>Q. Can non-KAIST students stay in a KAIST dormitory during the internship? A. Yes.</p> </li> <li> <p>Q. Can international students who are not enrolled in any Korean institutions apply? A. Yes, KAIST has a Visiting Student Researcher Program, although it is preferred for students who intend to undertake a longer-term internship (at least six months).</p> </li> </ul> <p> Back to top</p> <p></p>"},{"location":"join_us/","title":"Join Us","text":""},{"location":"join_us/#call-for-graduate-students-spring-2026","title":"Call for Graduate Students (Spring 2026)","text":""},{"location":"join_us/#application-deadline-october-12-2025-sunday-2359-kst","title":"Application Deadline: October 12, 2025 (Sunday), 23:59 KST.","text":"<p>Application Form </p>"},{"location":"join_us/#join-our-group","title":"Join Our Group!","text":""},{"location":"join_us/#introduction-to-the-kaist-visual-ai-group","title":"Introduction to the KAIST Visual AI Group","text":"<p>In our group, we mainly research machine learning technologies for visual data. We currently focus on three main research topics (while not limited to these, we explore a wider range related to them):</p> <ul> <li>Generative AI</li> <li>Spatial Intelligence</li> <li>Multimodal Foundation Models</li> </ul> <p>Please check out our recent publications here. We actively publish papers in the following top-tier conferences in Machine Learning, Computer Vision, and Computer Graphics:</p> <ul> <li>ML: NeurIPS, ICML, ICLR</li> <li>CV: CVPR, ICCV, ECCV</li> <li>CG: SIGGRAPH, SIGGRAPH Asia</li> </ul> <p>To find more information about our group, visit the followings:</p> <ul> <li>Group introduction slides (September 2025)</li> <li>Minhyuk's recent talk slides</li> <li>Publications page</li> <li>Course webpages<ul> <li>Diffusion and Flow Models (Fall 2025)</li> <li>Machine Learning for 3D Data (Spring 2025)</li> </ul> </li> </ul>"},{"location":"join_us/#openings","title":"Openings","text":""},{"location":"join_us/#international-applicants","title":"International Applicants","text":"<p>For international applicants, we have special openings with no limitations on the available slots. Please contact us before applying for the Master\u2019s program.</p>"},{"location":"join_us/#korean-applicants","title":"Korean Applicants","text":"<p>For Korean applicants, we currently have year-round openings (for both Spring and Fall) for:</p> <ul> <li>Two government-funded School of Computing Master's students,</li> <li>One KAIST scholarship School of Computing Master's student,</li> <li>One KAIST scholarship AI Graduate School  Master's student, and</li> <li>One Metaverse Graduate School Master's student</li> </ul> <p>Using the KAIST scholarship openings is exceptional. To join our group, we recommend applying for the government-funded School of Computing Master's program or contacting us before applying.</p>"},{"location":"join_us/#spring-vs-fall-admissions","title":"Spring vs. Fall Admissions","text":"<p>During the Fall admissions, only remaining openings that were not filled during the Spring admissions can be used. Therefore, we recommend applying in the Spring admissions. The likelihood of having openings for Fall applicants is low. If you must apply for the Fall admissions, please contact us by the summer (August) of the previous year.</p> <p>If you have questions about which openings would be best to apply for, please reach out to us.</p>"},{"location":"join_us/#recruiting-criteria","title":"Recruiting Criteria","text":"<p>We recruit Master\u2019s students who are willing to pursue a Ph.D. in our group. Students who have demonstrated strong performance through internships in our group will be given priority; however, we do not automatically select all students who have interned with us. Currently, approximately 30% of our graduate students joined without having interned in the group. Next, we prioritize students who have performed well in our courses. You can check the courses in the courses page.</p> <p>We consider the following aspects: (* number: Importance)</p> <ul> <li>Motivation (***): Your reasons for wanting to conduct research in our group and the kind of research you wish to pursue.</li> <li>Knowledge (**): Relevant courses taken and grades received, or level of related knowledge, including:<ul> <li>Linear algebra, probability and statistics, optimization, discrete mathematics, etc.</li> <li>Machine learning, deep learning, computer graphics, computer vision, etc.</li> </ul> </li> <li>Programming Skills (**): Experience with PyTorch, TensorFlow, Python, C++, etc.</li> <li>Communication skills (**)</li> <li>GPA (*): Overall GPA and grades in relevant courses.</li> <li>Experience (*): Participation in related research projects and internships, particularly in our group.</li> </ul>"},{"location":"join_us/#recruiting-process","title":"Recruiting Process","text":"<ul> <li> <p>Please do not send a contact email without any questions. Note that our recruiting process begins after the university's admission decision.</p> </li> <li> <p>If you are curious about which openings would be best for you to apply for, or how many openings remain for late admissions, please contact us.</p> </li> <li> <p>When applying to our group, you will be asked to submit your KAIST graduate school application, transcript, and CV. Please ensure you have these documents prepared.</p> </li> <li> <p>If you are interested in our group, we highly recommend applying for an internship in our group first.</p> </li> </ul>"},{"location":"join_us/#internships-in-our-group","title":"Internships in Our Group","text":"<p>We recruit undergraduate interns every summer and winter. Please check out the internship information here</p> <p> [Back to top]</p> <p></p>"},{"location":"members/","title":"Members","text":""},{"location":"members/#members","title":"Members","text":""},{"location":"members/#professor","title":"Professor","text":"<p>Minhyuk Sung Associate Professor CV image/svg+xml CV CV </p>"},{"location":"members/#phd-students","title":"Ph.D. Students","text":"<p>Juil Koo Ph.D. Student CV image/svg+xml CV CV </p> <p></p> <p>Jaihoon Kim Ph.D. Student CV image/svg+xml CV CV </p> <p></p> <p>Seungwoo Yoo Ph.D. Student CV image/svg+xml CV CV </p> <p></p> <p>Phillip (Yuseung) Lee Ph.D. Student CV image/svg+xml CV CV </p>"},{"location":"members/#masters-students","title":"Master's Students","text":"<p>Jisung Hwang M.S. Student </p> <p></p> <p>Taehoon Yoon M.S. Student </p> <p></p> <p>Mingue Park M.S. Student </p> <p></p> <p>Chanho Park M.S. Student </p> <p></p> <p>Prin Phunyaphibarn M.S. Student </p> <p></p> <p>Daehyeon Choi M.S. Student CV image/svg+xml CV CV </p> <p></p> <p>Yunhong Min M.S. Student CV image/svg+xml CV CV </p> <p></p> <p>Seoyoung Hwang M.S. Student </p>"},{"location":"members/#undergraduate-students","title":"Undergraduate Students","text":"<p>Kyeongmin Yeo Undergraduate Student </p> <p>Sangwoo Youn</p>"},{"location":"members/#former-graduate-students","title":"Former Graduate Students","text":"<p>Hyunjin Kim M.S. Student  Now at KRAFTON </p> <p></p> <p>Kunho Kim M.S. Student  Now at RebuilderAI </p> <p></p> <p>Eunji Hong M.S. Student  Now at NAVER LABS </p>"},{"location":"members/#visitors","title":"Visitors","text":"<p>Nail Ibrahimli  May 2025 - Present </p> <p>Wei-Tung Lin  Sep 2024 - Jan 2025 </p> <p>Daniel Korth  Mar 2024 - Jul 2024 </p> <p>Jihyeon Je  Jun 2023 - Aug 2023   Now Ph.D. Student at Stanford </p> <p></p>"},{"location":"news/","title":"News","text":"<ul> <li> <p>[Sep 2025] Five papers have been accepted to NeurIPS 2025, including one spotlight.</p> </li> <li> <p>[Sep 2025] One paper has been accepted to WACV 2026.</p> </li> <li> <p>[Aug 2025] Minhyuk talked about \"The Present and Future of Content Generation\" at the KAIST AI Transformation Workshop. Click to check out the recording.</p> </li> <li> <p>[Aug 2025] Minhyuk gave talks at NVIDIA, Google, Stanford, and SFU titled \"Inference-Time Guided Generation Using Diffusion and Flow Models\". Click to download the slides.</p> </li> <li> <p>[Jul 2025] Minhyuk gave lectures on diffusion models at MLSS-Senegal 2025.</p> </li> <li> <p>[Jun 2025] One paper has been accepted to ICCV 2025.</p> </li> <li> <p>[Jun 2025] One paper has been accepted to TMLR.</p> </li> <li> <p>[Apr 2025] Minhyuk gave a keynote talk at CVM 2025 titled \"Inference-Time Guided Generation with Diffusion and Flow Models\". Click to download the slides.</p> </li> <li> <p>[Jan 2025] One paper has been accepted to ICLR 2025.</p> </li> <li> <p>[Dec 2024] Minhyuk gave a talk at the University of Tokyo on \"Visual Content Generation with Image Diffusion Models\".</p> </li> <li> <p>[Sep 2024] Four papers have been accepted to NeurIPS 2024.</p> </li> <li> <p>[Sep 2024] Minhyuk won the Asiagraphics Young Researcher Award in 2024.</p> </li> <li> <p>[Sep 2024] One paper has been accepted at SIGGRAPH Asia 2024.</p> </li> <li> <p>[Aug 2024] Juil's Posterior Distillation Sampling received the Best Paper Award at the 2024 Samsung Electronics DS-KAIST R&amp;D Exchange Meeting.</p> </li> <li> <p>[Aug 2024] Minhyuk presented a tutorial on \"Diffusion Models for Visual Content Generation\" at SIGGRAPH 2024. Click here for more details.</p> </li> <li> <p>[Jul 2024] Minhyuk gave talks at Stanford and Adobe Research on \"Visual Content Generation with Image Diffusion Models\". Click here to download the slides.</p> </li> <li> <p>[Jul 2024] Two papers have been accepted at ECCV 2024.</p> </li> <li> <p>[Jun 2024] Minhyuk presented at the 2nd Workshop on Compositional 3D Vision (C3DV) at CVPR 2024. Click here to download the slides.</p> </li> <li> <p>[Apr 2024] Minhyuk gave talks at TUM, ETH, and \u00c9cole Polytechnique on Visual Content Generation with Image Diffusion Models. Click here to download the slides.</p> </li> <li> <p>[Apr 2024] Minhyuk gave a tutorial on \"Diffusion Models for Visual Computing\" at Eurographics 2024. Click here for more details.</p> </li> <li> <p>[Apr 2024] Seungwoo has been awarded the Presidential Science Scholarship. Congrats!</p> </li> <li> <p>[Feb 2024] Three papers have been accepted at CVPR 2024.</p> </li> <li> <p>[Dec 2023] Minhyuk gave a talk at NVIDIA Toronto AI Lab with the title: \"Moving Beyond 3D Generation to Editing with Image Diffusion Priors\". Click here to download the slides.</p> </li> <li> <p>[Oct 2023] One paper has been accepted at 3DV 2024.</p> </li> <li> <p>[Oct 2023] Minhyuk presented a tutorial at Pacific Graphics 2023 about 3D generative models. Click here for more details.</p> </li> <li> <p>[Oct 2023] Minhyuk gave a talk at University College London and Adobe Research Paris with the title: \"Towards Shape Editability and Multi-View Consistency in 3D Generation\". Click here to download the slides.</p> </li> <li> <p>[Sep 2023] Two papers have been accepted at NeurIPS 2023. Congratulations Yuseung on the first paper! Please check out our Hugging Face demo on our project webpage by clicking here.</p> </li> <li> <p>[Aug 2023] OptCtrlPoints has been accepted to Pacific Graphics 2023 as a full paper. Congrats Kunho!</p> </li> <li> <p>[Jul 2023] SALAD has been accepted at ICCV 2023. Kudos to Juil, Seungwoo, and Hieu! Click here to check out our Hugging Face demo on our project webpage.</p> </li> <li> <p>[Jul 2023] Minhyuk presented a tutorial talk at the Korea AI Association conference titled \"3D Generation via 2D Priors and Neural Rendering: Recent Advances, Limitations, and Future Directions.\" Click here to download the slides.</p> </li> <li> <p>[Jun 2023] Minhyuk gave a talk about 3D generative models at the POSTECH CSE/GSAI seminar series. Click to download the slides.</p> </li> <li> <p>[Apr 2023] Minhyuk is serving as a technical paper committee member at SIGGRAPH Asia 2023.</p> </li> <li> <p>[Apr 2023] Minhyuk is serving as a program committee member and a local arrangement chair at Pacific Graphics 2023.</p> </li> <li> <p>[Mar 2023] Minhyuk is co-organizing a workshop at CVPR 2023: Structural and Compositional Learning on 3D Data. Click here for more details.</p> </li> <li> <p>[Feb 2023] Two papers have been accepted at CVPR 2023.</p> </li> <li> <p>[Feb 2023] Juil\u2019s Master\u2019s thesis was awarded the outstanding thesis award.</p> </li> <li> <p>[Nov 2022] We are hosting KAIST Geometric and Visual Computing Workshop (GVC Workshop). Click this for more details.</p> </li> <li> <p>[Nov 2022] Minhyuk gave a talk about language and 3D &amp; differential Poisson Solver at the KAIST GSAI Colloquium. Click to download the slides.</p> </li> <li> <p>[Nov 2022] Juil received the Qualcomm Innovation Fellowship Korea (QIFK) 2022 for his PartGlot paper.</p> </li> <li> <p>[Oct 2022] One paper has been accepted at WACV 2023 (Algorithm Track).</p> </li> <li> <p>[Oct 2022] One paper has been accepted at Findings of EMNLP 2022.</p> </li> <li> <p>[Sep 2022] Minhyuk is serving as a senior program committee member at AAAI 2023.</p> </li> <li> <p>[Aug 2022] We are hosting the 2022 Women Tech Stars workshop at KAIST, supported by the Google ExploreCSR program. Click this to check out the webpage.</p> </li> <li> <p>[Aug 2022] Minhyuk is serving as an associate editor of Graphical Models.</p> </li> <li> <p>[Aug 2022] Minhyuk wrote a blog post about 'How do I structure a paper?' at SIGGRAPH Research Career Development Committee (RCDC) webpage. Click to check it out.</p> </li> <li> <p>[Jul 2022] Juil won an outstanding paper award at Korea Computer Graphics Society (KCGS 2022).</p> </li> <li> <p>[Jul 2022] Minhyuk presented a keynote talk at the ICME Workshop on 3D Multimedia Analytics, Search and Generation. Click here for more details.</p> </li> <li> <p>[Jul 2022] Minhyuk gave a lecture on \"Introduction to Neural Rendering\" at the Summer School of KCGS 2022. Click to download the slides.</p> </li> <li> <p>[Jul 2022] One paper has been accepted at ECCV 2022.</p> </li> <li> <p>[Jun 2022] Minhyuk gave a talk about language and 3D at Stanford University. Click to download the slides.</p> </li> <li> <p>[Apr 2022] Minhyuk is serving as a technical paper committee member at SIGGRAPH Asia 2022.</p> </li> <li> <p>[Mar 2021] Three papers have been accepted at CVPR 2022 including Juil's oral.</p> </li> <li> <p>[Feb 2022] Minhyuk gave a talk at Asiagraphics as a webinar speaker. Click here for more details.</p> </li> <li> <p>[Feb 2022] One paper has been accepted at ICRA 2022.</p> </li> <li> <p>[Sep 2021] Minhyuk is serving as an International Program Committee member at Eurographics 2022.</p> </li> <li> <p>[Sep 2021] We have been awarded the Google exploreCSR grant for the Rising Stars 2022 program at KAIST. Stay tuned for the details of the event!</p> </li> <li> <p>[Jul 2021] Two papers have been accepted at ICCV 2021.</p> </li> <li> <p>[Apr 2021] Minhyuk is co-organizing a workshop at ICCV 2021: Structural and Compositional Learning on 3D Data. Click here for more details.</p> </li> <li> <p>[Mar 2021] Three papers have been accepted at CVPR 2021 including two orals.</p> </li> <li> <p>[Jan 2021] We've just launched our group at KAIST!</p> </li> </ul> <p></p>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#publications","title":"Publications","text":""},{"location":"publications/#2026","title":"2026","text":"<p>Unconditional Priors Matter! Improving Conditional Generation of Fine-Tuned Diffusion Models Prin Phunyaphibarn, Phillip Y. Lee, Jaihoon Kim, Minhyuk Sung WACV 2026  Project arXiv PDF </p>"},{"location":"publications/#2025","title":"2025","text":"<p>\u03a8-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models Taehoon Yoon*, Yunhong Min*, Kyeongmin Yeo*, Minhyuk Sung (* equal contributions) NeurIPS 2025 (Spotlight) Project arXiv PDF Code </p> <p></p> <p>Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing Jaihoon Kim*, Taehoon Yoon*, Jisung Hwang*, Minhyuk Sung (* equal contributions) NeurIPS 2025  Project arXiv Code </p> <p></p> <p>ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation Yunhong Min*, Daehyeon Choi*, Kyeongmin Yeo, Jihyun Lee, Minhyuk Sung (* equal contributions) NeurIPS 2025  Project arXiv Code </p> <p></p> <p>Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models  Jisung Hwang, Jaihoon Kim, Minhyuk Sung NeurIPS 2025  arXiv </p> <p></p> <p>Neural Green\u2019s Functions for Solving Poisson\u2019s Equation Seungwoo Yoo, Kyeongmin Yeo, Jisung Hwang, Minhyuk Sung NeurIPS 2025 </p> <p></p> <p>Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung ICCV 2025  Project arXiv PDF Code </p> <p></p> <p>MemBench: Memorized Image Trigger Prompt Dataset for Diffusion Models Chunsan Hong, Tae-Hyun Oh*, Minhyuk Sung* (* co-corresponding authors) TMLR  arXiv PDF Code </p> <p></p> <p>VideoHandles: Editing 3D Object Compositions in Videos Using Video Generative Priors Juil Koo, Paul Guerrero, Chun-Hao Paul Huang, Duygu Ceylan, Minhyuk Sung CVPR 2025  Project arXiv PDF </p> <p></p> <p>REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning Jihyun Lee, Weipeng Xu, Alexander Richard, Shih-En Wei, Shunsuke Saito, Shaojie Bai, Te-Li Wang, Minhyuk Sung, Tae-Kyun Kim, Jason Saragih CVPR 2025  Project arXiv </p> <p></p> <p>StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces  Kyeongmin Yeo*, Jaihoon Kim*, Minhyuk Sung (* equal contributions) ICLR 2025  Project arXiv Code </p>"},{"location":"publications/#2024","title":"2024","text":"<p>SyncTweedies: A General Generative Framework Based on Synchronized Diffusions Jaihoon Kim*, Juil Koo*, Kyeongmin Yeo*, Minhyuk Sung (* equal contributions) NeurIPS 2024  Project arXiv PDF Code </p> <p></p> <p>Neural Pose Representation Learning for Generating and Transferring Non-Rigid Object Poses Seungwoo Yoo, Juil Koo, Kyeongmin Yeo, Minhyuk Sung NeurIPS 2024  Project arXiv </p> <p></p> <p>GrounDiT: Grounding Diffusion Transformers via Noisy Patch Transplantation Phillip Y. Lee*, Taehoon Yoon*, Minhyuk Sung (* equal contributions) NeurIPS 2024  Project arXiv Code </p> <p></p> <p>MV2Cyl: Reconstructing 3D Extrusion Cylinders from Multi-View Images  Eunji Hong, Nguyen Minh Hieu, Mikaela Angelina Uy, Minhyuk Sung NeurIPS 2024  arXiv </p> <p></p> <p>Occupancy-Based Dual Contouring  Jisung Hwang, Minhyuk Sung SIGGRAPH Asia 2024  Project arXiv Code </p> <p></p> <p>ReGround: Improving Textual and Spatial Grounding at No Cost Phillip Y. Lee, Minhyuk Sung ECCV 2024  Project arXiv PDF </p> <p></p> <p>PartSTAD: 2D-to-3D Part Segmentation Task Adaptation Hyunjin Kim, Minhyuk Sung ECCV 2024  Project arXiv Code </p> <p></p> <p>Posterior Distillation Sampling Juil Koo, Chanho Park, Minhyuk Sung CVPR 2024  Project arXiv PDF Code </p> <p></p> <p>As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion Priors Seungwoo Yoo*, Kunho Kim*, Vladimir Kim, Minhyuk Sung (* equal contributions) CVPR 2024  Project arXiv PDF Code </p> <p></p> <p>InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion Jihyun Lee, Shunsuke Saito, Giljoo Nam, Minhyuk Sung, Tae-Kyun Kim CVPR 2024  Project arXiv PDF Code </p> <p></p> <p>Split, Merge, and Refine: Fitting Tight Bounding Boxes via Learned Over-Segmentation and Iterative Search  Chanhyeok Park, Minhyuk Sung 3DV 2024  arXiv </p>"},{"location":"publications/#2023","title":"2023","text":"<p>SyncDiffusion: Coherent Montage via Synchronized Joint Diffusions Yuseung Lee, Kunho Kim, Hyunjin Kim, Minhyuk Sung NeurIPS 2023  Project arXiv PDF Code Hugging Face </p> <p></p> <p>FourierHandFlow: Neural 4D Hand Representation Using Fourier Query Flow Jihyun Lee, Junbong Jang, Donghwan Kim, Minhyuk Sung, Tae-Kyun Kim NeurIPS 2023  Project arXiv </p> <p></p> <p>OptCtrlPoints: Optimizing Control Points for Biharmonic 3D Shape Deformation  Kunho Kim*, Mikaela Angelina Uy*, Despoina Paschalidou, Alec Jacobson, Leonidas Guibas, Minhyuk Sung (* equal contributions) Pacific Graphics 2023  Project arXiv PDF Slides Video </p> <p></p> <p>SALAD: Part-Level Latent Diffusion for 3D Shape Generation and Manipulation Juil Koo*, Seungwoo Yoo*, Minh Hieu Nguyen*, Minhyuk Sung (* equal contributions) ICCV 2023  Project arXiv PDF Code Hugging Face </p> <p></p> <p>Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes Jihyun Lee, Minhyuk Sung, Honggyu Choi, Tae-Kyun Kim CVPR 2023  Project arXiv </p> <p></p> <p>ShapeTalk: A Language Dataset and Framework for 3D Shape Edits and Deformations Panos Achlioptas, Ian Huang, Minhyuk Sung, Sergey Tulyakov, Leonidas Guibas CVPR 2023  Project PDF </p> <p></p> <p>Seg&amp;Struct: The Interplay Between Part Segmentation and Structure Inference for 3D Shape Parsing  Junghyun Kim, Kaichun Mo, Minhyuk Sung*, Woontack Woo* (* co-corresponding authors) WACV 2023  Project arXiv Poster Video </p>"},{"location":"publications/#2022","title":"2022","text":"<p>LADIS: Language Disentanglement for 3D Shape Editing Ian Huang, Panos Achlioptas, Tianyi Zhang, Sergei Tulyakov, Minhyuk Sung, Leonidas Guibas Findings of EMNLP 2022  arXiv PDF Code </p> <p></p> <p>The Shape Part Slot Machine: Contact-based Reasoning for Generating 3D Shapes from Parts Kai Wang, Paul Guerrero, Vladimir Kim, Siddhartha Chaudhuri, Minhyuk Sung, Daniel Ritchie ECCV 2022  arXiv Code </p> <p></p> <p>PartGlot: Learning Shape Part Segmentation from Language Reference Games Juil Koo, Ian Huang, Panos Achlioptas, Leonidas Guibas, Minhyuk Sung CVPR 2022 (Oral) Project arXiv Video Code </p> <p></p> <p>Pop-Out Motion: 3D-Aware Image Deformation via Learning the Shape Laplacian Jihyun Lee*, Minhyuk Sung*, Hyunjin Kim, Tae-Kyun Kim (* equal contributions) CVPR 2022  Project arXiv Video Code </p> <p></p> <p>Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders Mikaela Angelina Uy*, Yen-yu Chang*, Minhyuk Sung, Purvi Goel, Joseph Lambourne, Tolga Birdal, Leonidas Guibas (* equal contributions) CVPR 2022  Project arXiv Poster Video Code </p>"},{"location":"publications/#2021","title":"2021","text":"<p>Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction Youngsun Kwon, Minhyuk Sung*, Sung-Eui Yoon* (* co-corresponding authors) ICRA 2022  Project arXiv PDF Code </p> <p></p> <p>CPFN: Cascaded Primitive Fitting Networks for High-Resolution Point Clouds Eric-Tuan L\u00ea, Minhyuk Sung, Duygu Ceylan, Radom\u00edr M\u011bch, Tamy Boubekeur, Niloy Mitra ICCV 2021  arXiv Code </p> <p></p> <p>CTRL-C: Camera calibration TRansformer with Line-Classification  Jinwoo Lee, Hyunsung Go, Hyunjoon Lee, Sunghyun Cho, Minhyuk Sung, Junho Kim ICCV 2021  arXiv Code </p> <p></p> <p>DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates Minghua Liu, Minhyuk Sung, Radom\u00edr M\u011bch, Hao Su CVPR 2021 (Oral) Project arXiv Web Demo Supplementary Code </p> <p></p> <p>MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization Jiahui Huang, He Wang, Tolga Birdal, Minhyuk Sung, Federica Arrigoni, Shi-Min Hu, Leonidas Guibas CVPR 2021 (Oral) Project arXiv Code </p> <p></p> <p>Joint Learning of 3D Shape Retrieval and Deformation Mikaela Angelina Uy, Vladimir G. Kim, Minhyuk Sung, Noam Aigerman, Siddhartha Chaudhuri, Leonidas Guibas CVPR 2021  Project arXiv Code </p>"},{"location":"publications/#2020-and-before","title":"2020 and Before","text":"<p>DeformSyncNet: Deformation Transfer via Synchronized Shape Deformation Spaces  Minhyuk Sung, Zhenyu Jiang, Panos Achlioptas, Niloy Mitra, Leonidas Guibas (* equal contributions) SIGGRAPH Asia 2020  Project arXiv Code <p></p> <p>Deformation-Aware 3D Shape Embedding and Retrieval Mikaela Angelina Uy, Jingwei Huang, Minhyuk Sung, Tolga Birdal, Leonidas Guibas ECCV 2020  Project arXiv Slides Code </p> <p></p> <p>Neural Geometric Parser for Single Image Camera Calibration  Jinwoo Lee, Minhyuk Sung, Hyunjoon Lee, Junho Kim ECCV 2020  arXiv </p> <p></p> <p>Pix2Surf: Learning Parametric 3D Surface Models of Objects from Images Jiahui Lei, Srinath Sridhar, Paul Guerrero, Minhyuk Sung, Niloy Mitra, Leonidas Guibas ECCV 2020  Project arXiv PDF Supplementary Code </p> <p></p> <p>Learning 3D Part Assembly from a Single Image Yichen Li*, Kaichun Mo*, Lin Shao, Minhyuk Sung, Leonidas Guibas (* equal contributions) ECCV 2020  Project arXiv Slides Code </p> <p></p> <p>Learning and Exploring the Compositional Structure of 3D Data Minhyuk Sung Ph.D. Dissertation. Stanford University. 2019.  Link </p> <p></p> <p>Supervised Fitting of Geometric Primitives to 3D Point Clouds Lingxiao Li*, Minhyuk Sung*, Anastasia Dubrovina, Li Yi, Leonidas Guibas (* equal contributions) CVPR 2019 (Oral) arXiv Video Code </p> <p></p> <p>GSPN: Generative Shape Proposal Network for 3D Instance Segmentation in Point Cloud Li Yi, Wang Zhao, He Wang, Minhyuk Sung, Leonidas Guibas CVPR 2019  arXiv Code </p> <p></p> <p>Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions Minhyuk Sung, Hao Su, Ronald Yu, Leonidas Guibas NeurIPS 2018  arXiv PDF Poster Code </p> <p></p> <p>Learning Fuzzy Set Representations of Partial Shapes on Dual Embedding Spaces Minhyuk Sung, Anastasia Dubrovina, Vladimir G. Kim, Leonidas Guibas SGP 2018  Project arXiv PDF Slides Code </p> <p></p> <p>ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling Minhyuk Sung, Hao Su, Vladimir G. Kim, Siddhartha Chaudhuri, Leonidas Guibas SIGGRAPH Asia 2017 (Featured in an ACM press release) Project arXiv PDF Slides Code Media 1 Media 2 </p> <p></p> <p>Data-Driven Structural Priors for Shape Completion Minhyuk Sung, Vladimir G. Kim, Roland Angst, Leonidas Guibas SIGGRAPH Asia 2015  Project PDF Slides Supplementary Code </p> <p></p> <p>Image Unprojection for 3D Surface Reconstruction: A Triangulation-based Approach Min-Hyuk Sung, Hwasup Lim, Hyoung-Gon Kim, Sang Chul Ahn ICIP 2013  Link </p> <p></p> <p>Finding the M-best consistent correspondences between 3D symmetric objects Min-Hyuk Sung, Junho Kim Computers &amp; Graphics 2013  Link </p> <p></p> <p>A Triangulation-Invariant Method for Anisotropic Geodesic Map Computation on Surface Meshes  Sang Wook Yoo, Joon-Kyung Seong, Min-Hyuk Sung, Sung Yong Shin, Elaine Cohen TVCG 2012  Link </p> <p></p> <p>A Spectral Approach to Shape Matching Using a Heat Kernel Function Min-Hyuk Sung M.S. Thesis. KAIST. 2010.  Link </p> <p></p>"}]}